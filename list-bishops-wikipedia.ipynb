{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bishop Data Collection Automation Framework\n",
    "\n",
    "This notebook provides a basic framework for scraping the relevant data from Wikipedia pages where those pages include lists of bishops for specific dioceses. It can collect from a few basic list formats, but it may not work well with tables or other data sources. As I try to run it on more pages I will try to expand its scope to account for these.\n",
    "\n",
    "Note: The final collection function takes a 'path' argument to enable the selenium webdriver; this path is generally something like '/Users/*yourname*/Downloads/chromedriver'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *CURRENT ISSUES*\n",
    "\n",
    "1. There was an error when using the *googletrans Translator*; I have not looked into this further, so for now I have commented out that code, and simply instruct *bio_collector* to include a blank \"English Bio\" field\n",
    "\n",
    "2. I have not accounted for the binary *Archbishop* column yet... not sure how to do that... maybe we can check Yada's code? https://github.com/pruksmhc/JobDioceScrape/blob/master/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section I: Definition of Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package import cell\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from googletrans import Translator\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to collect data from well-defined list Wikis and store in dictionary\n",
    "def list_collector(path, url):\n",
    "    primary_url = url\n",
    "    driver = webdriver.Chrome(executable_path = path)\n",
    "    driver.get(primary_url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    driver.close()\n",
    "    soup_bishops = soup.select('li')\n",
    "    bishops_with_links = {}\n",
    "    for bishop in soup_bishops:\n",
    "        if bishop.findChildren('a'):\n",
    "            bishops_with_links[bishop.text] = 'https://de.wikipedia.org' + bishop.a.get('href')\n",
    "        else:\n",
    "            bishops_with_links[bishop.text] = ''\n",
    "    for bishop, link in bishops_with_links.items():\n",
    "        if (('redlink' in link) | ('index' in link)):\n",
    "            bishops_with_links[bishop] = ''\n",
    "    return bishops_with_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to clean bishop data string and return name, year in, year out\n",
    "def cleaner(string):\n",
    "    string = string.replace('ca. ', '').replace('um ', '').replace('seit ', '')\n",
    "    string = string.replace(' –', '–')\n",
    "    string = string.replace('– ', '–')\n",
    "    string = string.replace('- ', '–')\n",
    "    string = string.replace(' -', '–')\n",
    "    string = string.replace('0000', '–')\n",
    "    string = string.replace(':', '')\n",
    "    string = string.replace('vakant', 'Vacant')\n",
    "    string = re.sub(r' ?\\([^)]+\\)', '', string)\n",
    "    if string[0:3].isdigit():\n",
    "        string_elements = string.split(' ')\n",
    "        years = string_elements[0]\n",
    "        if '–' in years:    \n",
    "            year_elements = years.split('–')\n",
    "            year_in = year_elements[0]\n",
    "            year_out = year_elements[1]\n",
    "        else:\n",
    "            year_in = years\n",
    "            year_out = ''\n",
    "        name = ' '.join(string_elements[1:])\n",
    "        string = name+':'+year_in+':'+year_out\n",
    "    elif ((string[-3:].isdigit()) | (string.endswith('??'))):\n",
    "        string_elements = string.split(' ')\n",
    "        years = string_elements[-1]\n",
    "        if '–' in years:    \n",
    "            year_elements = years.split('–')\n",
    "            year_in = year_elements[0]\n",
    "            year_out = year_elements[1]\n",
    "        else:\n",
    "            year_in = years\n",
    "            year_out = ''\n",
    "        name = ' '.join(string_elements[:-1])\n",
    "        string = name+':'+year_in+':'+year_out\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to set up dataframe, pull in dictionary and clean\n",
    "def dataframer(dictionary):\n",
    "    bishops = pd.DataFrame()\n",
    "    bishops['Name'] = dictionary.keys()\n",
    "    bishops['Name'] = bishops['Name'].apply(cleaner)\n",
    "    bishops = pd.DataFrame(bishops['Name'].str.split(':').tolist(), columns = ['Name','From', 'To'])\n",
    "    bishops['From'] = bishops['From'].astype(str)\n",
    "    bishops['To'] = bishops['To'].astype(str)\n",
    "    bishops['Bio Link'] = dictionary.values()\n",
    "    bishops = bishops[(~bishops['From'].str.startswith('17')) & (~bishops['From'].str.startswith('18')) \n",
    "                      & (~bishops['From'].str.startswith('19')) & (~bishops['From'].str.startswith('2')) \n",
    "                      & (~bishops['From'].str.startswith('None')) & (~bishops['To'].str.startswith('None'))\n",
    "                      & (~bishops['To'].str.startswith('18')) & (~bishops['To'].str.startswith('19'))\n",
    "                      & (~bishops['To'].str.startswith('2'))] \n",
    "    bishops = bishops.dropna()\n",
    "    return bishops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process available links and collect biographies in dataframe\n",
    "def bio_collector(path, dataframe):\n",
    "    bio_list = []\n",
    "    for link in dataframe['Bio Link']:\n",
    "        if link != '':\n",
    "            driver = webdriver.Chrome(executable_path = path)\n",
    "            driver.get(link)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            driver.close()\n",
    "            paragraphs = soup.find_all('p')\n",
    "            german_bio = ' '.join(paragraph.text for paragraph in paragraphs).replace('\\n', ' ')\n",
    "            english_bio = ''\n",
    "            bio_list.append([link, german_bio, english_bio])\n",
    "    bio_dataframe = pd.DataFrame.from_records(bio_list)\n",
    "    bio_dataframe = bio_dataframe.rename({0:'Bio Link', 1:'German Bio', 2:'English Bio'}, axis='columns')\n",
    "    return bio_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create final, merged, clean dataframe\n",
    "def merger(bishop_dataframe, bio_dataframe):\n",
    "    if not bio_dataframe.empty:\n",
    "        final = pd.merge(bishop_dataframe, bio_dataframe, on='Bio Link', how='left')\n",
    "        final = final.fillna('')\n",
    "    else:\n",
    "        final = bishop_dataframe\n",
    "        final['German Bio'] = ''\n",
    "        final['English Bio'] = ''\n",
    "        final = final.fillna('')\n",
    "    final['Name First Letter'] = ''\n",
    "    final['Bio First Letter'] = ''\n",
    "    final['Name First Letter'] = final['Name'].str.slice(start=0, stop=1)\n",
    "    final['Bio First Letter'] = final['German Bio'].str.slice(start=0, stop=1)\n",
    "    final['Bio Link'] = np.where((final['Name First Letter'] != final['Bio First Letter']),\n",
    "                                 '', final['Bio Link'])\n",
    "    final['German Bio'] = np.where((final['Name First Letter'] != final['Bio First Letter']), \n",
    "                                   '', final['German Bio'])\n",
    "    final = final.drop(columns=['Name First Letter', 'Bio First Letter'])\n",
    "    final = final.drop_duplicates(subset='Name')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to translate German column to English column\n",
    "def translator(dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "        translator = Translator()\n",
    "        english_bio = translator.translate(row['German Bio'], src='de', dest='en').text\n",
    "        row['English Bio'] = english_bio\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to automate the collection process for a given diocese using above functions\n",
    "def collector(path, url, country, diocese):\n",
    "    bishops = list_collector(path, url)\n",
    "    bishop_dataframe = dataframer(bishops)\n",
    "    bio_dataframe = bio_collector(path, bishop_dataframe)\n",
    "    merged_dataframe = merger(bishop_dataframe, bio_dataframe)\n",
    "#     final_dataframe = translator(merged_dataframe)\n",
    "    final_dataframe = merged_dataframe\n",
    "    final_dataframe['Country'] = country\n",
    "    final_dataframe['Diocese'] = diocese\n",
    "    final_dataframe = final_dataframe.set_index(['Country', 'Diocese'])\n",
    "    return final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to concatenate dataframes for list of country dioceses\n",
    "def concatenator(path, input_list):\n",
    "    cumulator = collector(path, input_list[0][0], input_list[0][1], input_list[0][2])\n",
    "    for specs in input_list[1:]:\n",
    "        current = collector(path, specs[0], specs[1], specs[2])\n",
    "        cumulator = pd.concat([cumulator, current])\n",
    "    return cumulator   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to export final dataframe to CSV\n",
    "def exportify(dataframe, filename):\n",
    "    csv = dataframe.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section II: Build & Export CSV files by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = '/Users/orion/Downloads/chromedriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark = [['https://de.wikipedia.org/wiki/Bistum_Aalborg', 'Denmark', 'Aalborg'], \n",
    "           ['https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_Aarhus', 'Denmark', 'Aarhus'],\n",
    "           ['https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_der_F%C3%A4r%C3%B6er', 'Denmark', 'Faroer'],\n",
    "           ['https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_F%C3%BCnen', 'Denmark', 'Funen'],\n",
    "           ['https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_Gr%C3%B6nland', 'Denmark', 'Gronland'],\n",
    "           ['https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_Roskilde', 'Denmark', 'Roskilde'], \n",
    "           ['https://de.wikipedia.org/wiki/Bistum_Viborg', 'Denmark', 'Viborg']]\n",
    "\n",
    "finland = [['https://de.wikipedia.org/wiki/Liste_der_Erzbisch%C3%B6fe_von_Turku#Bisch%C3%B6fe_von_Turku_2', 'Finland', 'Turku']]\n",
    "\n",
    "iceland = [['https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_Sk%C3%A1lholt', 'Iceland', 'Skalholt']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark_dataframe = concatenator(mypath, denmark)\n",
    "exportify(denmark_dataframe, 'denmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "finland_dataframe = concatenator(mypath, finland)\n",
    "exportify(finland_dataframe, 'finland.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iceland_dataframe = concatenator(mypath, iceland)\n",
    "exportify(iceland_dataframe, 'iceland.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
