{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bishop Data Collection Automation Framework\n",
    "\n",
    "This notebook provides a basic framework for scraping the relevant data from Wikipedia pages where those pages include lists of bishops for specific dioceses. It can collect from a few basic list formats, but it may not work well with tables or other data sources. As I try to run it on more pages I will try to expand its scope to account for these.\n",
    "\n",
    "Note: The final collection function takes a 'path' argument to enable the selenium webdriver; this path is generally something like '/Users/*yourname*/Downloads/chromedriver'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *CURRENT ISSUES*\n",
    "\n",
    "1. References to other pages that incude a date in the *href* text (for example, the hyperlinked Weblink *Greenland in the Diplomatarium Norwegicum after 1364* on the page https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_Gr%C3%B6nland) get treated like bishops\n",
    "2. *link_collector* not working for *Ísleifur Gissurarson* on the page https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_Gr%C3%B6nland\n",
    "3. There was an error when using the *googletrans Translator*; I have not looked into this further, so for now I have commented out that code, and simply instruct *bio_collector* to include a blank \"English Bio\" field\n",
    "4. *bio_collector* does not work if the hyperlinked URL is not just the exact name from the list; for example, *Peder Jansen Lodehat* in *Aarhus* works, because the hyperlinked URL is just https://de.wikipedia.org/wiki/Peder_Jansen_Lodehat, but *Eskil* in *Roskilde* does not work because the hyperlinked URL is https://de.wikipedia.org/wiki/Eskil_von_Lund instead of just https://de.wikipedia.org/wiki/Eskil\n",
    "5. I have not accounted for the binary *Archbishop* column yet... not sure how to do that... maybe we can check Yada's code? https://github.com/pruksmhc/JobDioceScrape/blob/master/main.py\n",
    "6. I have not gotten to this stage yet because I wanted to go through a number of list pages for testing, but eventually I will write a function to loop through a list of per-diocese URLS and merge all DataFrames for a given country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package import cell\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from googletrans import Translator\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to collect data from well-defined list Wikis\n",
    "def list_collector(path, url):\n",
    "    primary_url = url\n",
    "    driver = webdriver.Chrome(executable_path = path)\n",
    "    driver.get(primary_url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    driver.close()\n",
    "    bishops = soup.find_all('li')\n",
    "    return bishops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to collect list text from list_collector\n",
    "def list_to_text(bishop_list):\n",
    "    bishop_list_text = [bishop.text for bishop in bishop_list]\n",
    "    return bishop_list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create merge-able dataframe of bishops with bio links\n",
    "def link_collector(bishop_list):\n",
    "    secondary_urls = {}\n",
    "    for bishop in bishop_list:\n",
    "        urls = bishop.findAll('a')\n",
    "        for a in urls:\n",
    "            if 'redlink' not in a['href']:\n",
    "                name = ' '.join(a['href'].split('/')[-1].split('_'))\n",
    "                url = 'https://de.wikipedia.org'+a['href']\n",
    "                secondary_urls.update({name:url})\n",
    "    bishops_with_bios = pd.DataFrame(list(secondary_urls.items()), columns=['Name', 'Bio Link'])\n",
    "    return bishops_with_bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert bishop list text to clean list of lists\n",
    "def list_cleaner(bishop_list_text):\n",
    "    clean_bishops = []\n",
    "    for bishop in bishop_list_text:\n",
    "        bishop = bishop.replace('ca. ', '').replace('um ', '').replace('seit ', '')\n",
    "        bishop = bishop.replace(' –', '–')\n",
    "        bishop = bishop.replace('– ', '–')\n",
    "        bishop = bishop.replace('- ', '–')\n",
    "        bishop = bishop.replace(' -', '–')\n",
    "        bishop = bishop.replace(':', '')\n",
    "        bishop = bishop.replace('vakant', 'Vacant')\n",
    "        bishop = re.sub(r' ?\\([^)]+\\)', '', bishop)\n",
    "        if bishop[0:3].isdigit():\n",
    "            bishop_elements = bishop.split(' ')\n",
    "            years = bishop_elements[0]\n",
    "            if '–' in years:    \n",
    "                year_elements = years.split('–')\n",
    "                year_in = year_elements[0]\n",
    "                year_out = year_elements[1]\n",
    "            else:\n",
    "                year_in = years\n",
    "                year_out = ''\n",
    "            name = ' '.join(bishop_elements[1:])\n",
    "            clean_bishops.append([name, year_in, year_out])\n",
    "        elif ((bishop[-3:].isdigit()) | (bishop.endswith('??'))):\n",
    "            bishop_elements = bishop.split(' ')\n",
    "            years = bishop_elements[-1]\n",
    "            if '–' in years:    \n",
    "                year_elements = years.split('–')\n",
    "                year_in = year_elements[0]\n",
    "                year_out = year_elements[1]\n",
    "            else:\n",
    "                year_in = years\n",
    "                year_out = ''\n",
    "            name = ' '.join(bishop_elements[:-1])\n",
    "            clean_bishops.append([name, year_in, year_out])\n",
    "    return clean_bishops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert clean list of lists to clean dataframe\n",
    "def dataframer(list_of_bishop_lists, country, diocese):\n",
    "    data = pd.DataFrame.from_records(list_of_bishop_lists)\n",
    "    data = data.rename({0:'Name', 1:'From', 2:'To'}, axis='columns')\n",
    "    data['Country'] = country\n",
    "    data['Diocese'] = diocese\n",
    "    data = data[(~data['From'].str.startswith('17')) & (~data['From'].str.startswith('18')) \n",
    "                & (~data['From'].str.startswith('19')) & (~data['From'].str.startswith('2')) \n",
    "                & (~data['From'].str.startswith('-'))]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to merge bishop dataframe with link dataframe\n",
    "def url_merger(bishop_dataframe, link_dataframe):\n",
    "    merged_dataframe = pd.merge(bishop_dataframe, link_dataframe, on='Name', how='left')\n",
    "    merged_dataframe = merged_dataframe.fillna('')\n",
    "    return merged_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process available links and collect biographies in dataframe\n",
    "def bio_collector(dataframe, path):\n",
    "    bio_list = []\n",
    "    for link in dataframe['Bio Link']:\n",
    "        if link != '':\n",
    "            driver = webdriver.Chrome(executable_path = path)\n",
    "            driver.get(link)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            driver.close()\n",
    "            name = ' '.join(link.split('/')[-1].split('_'))\n",
    "            paragraphs = soup.find_all('p')\n",
    "            gbio = ' '.join(paragraph.text for paragraph in paragraphs).replace('\\n', ' ')\n",
    "#             ebio = translator.translate(gbio, src='de', dest='en')\n",
    "            ebio = ''\n",
    "#             bio_list.append([name, gbio, ebio.text])\n",
    "            bio_list.append([name, gbio, ebio])\n",
    "    bio_dataframe = pd.DataFrame.from_records(bio_list)\n",
    "    bio_dataframe = bio_dataframe.rename({0:'Name', 1:'German Bio', 2:'English Bio'}, axis='columns')\n",
    "    return bio_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create final clean dataframe\n",
    "def dataframe_finalizer(bishop_dataframe, bio_dataframe):\n",
    "    if not bio_dataframe.empty:\n",
    "        final = pd.merge(bishop_dataframe, bio_dataframe, on='Name', how='left')\n",
    "        final = final.fillna('')\n",
    "    else:\n",
    "        final = bishop_dataframe\n",
    "        final['German Bio'] = ''\n",
    "        final['English Bio'] = ''\n",
    "        final = final.fillna('')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to automate the collection process using above functions\n",
    "def collector(path, url, country, diocese):\n",
    "    bishop_list = list_collector(path, url)\n",
    "    clean_bishop_list = list_cleaner(list_to_text(bishop_list))\n",
    "    clean_bishop_dataframe = dataframer(clean_bishop_list, country, diocese)\n",
    "    link_dataframe = link_collector(bishop_list)\n",
    "    merged_dataframe = url_merger(clean_bishop_dataframe, link_dataframe)\n",
    "    bio_dataframe = bio_collector(merged_dataframe, path)\n",
    "    output = dataframe_finalizer(merged_dataframe, bio_dataframe)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark_aarhus = collector('/Users/orion/Downloads/chromedriver', \n",
    "                           'https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_Aarhus', \n",
    "                           'Denmark', \n",
    "                           'Aarhus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark_funen = collector('/Users/orion/Downloads/chromedriver', \n",
    "                          'https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_F%C3%BCnen', \n",
    "                          'Denmark', \n",
    "                          'Funen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark_roskilde = collector('/Users/orion/Downloads/chromedriver', \n",
    "                             'https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_Roskilde', \n",
    "                             'Denmark', \n",
    "                             'Roskilde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark_viborg = collector('/Users/orion/Downloads/chromedriver', \n",
    "                           'https://de.wikipedia.org/wiki/Bistum_Viborg', \n",
    "                           'Denmark', \n",
    "                           'Viborg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark_aalborg = collector('/Users/orion/Downloads/chromedriver', \n",
    "                            'https://de.wikipedia.org/wiki/Bistum_Aalborg', \n",
    "                            'Denmark', \n",
    "                            'Aalborg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark_gronland = collector('/Users/orion/Downloads/chromedriver', \n",
    "                             'https://de.wikipedia.org/wiki/Liste_der_Bisch%C3%B6fe_von_Gr%C3%B6nland', \n",
    "                             'Denmark', \n",
    "                             'Gronland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
